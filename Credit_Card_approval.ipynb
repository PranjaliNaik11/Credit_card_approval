{
  "cells": [
    {
      "source": [
        "![Credit card being held in hand](credit_card.jpg)\n",
        "\n",
        "Commercial banks are inundated with a high volume of credit card applications, a significant portion of which are declined due to various factors such as elevated loan balances, insufficient income levels, or excessive inquiries on credit reports. The manual scrutiny of these applications is not only tedious and prone to errors but also consumes valuable time. Fortunately, leveraging machine learning technology automates this process, a practice now ubiquitous among commercial banks. In this workbook, you'll construct an automated credit card approval predictor using machine learning methodologies, mirroring the approach adopted by real-world financial institutions.\n",
        "\n",
        "### The Data\n",
        "\n",
        "The dataset provided is a condensed portion of the Credit Card Approval dataset sourced from the UCI Machine Learning Repository, depicting the array of credit card applications received by a bank. This dataset has been imported into a `pandas` DataFrame named `cc_apps`, with the final column representing the target value."
      ],
      "metadata": {
        "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13"
      },
      "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
      "cell_type": "markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the data"
      ],
      "metadata": {
        "id": "Ib4rN0GlExuo"
      },
      "id": "Ib4rN0GlExuo"
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the dataset\n",
        "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None)\n",
        "cc_apps.head()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 41,
        "lastExecutedAt": 1714671341373,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()",
        "outputsMetadata": {
          "0": {
            "height": 194,
            "type": "dataFrame"
          }
        },
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "visualizeDataframe": false,
        "chartConfig": {
          "bar": {
            "hasRoundedCorners": true,
            "stacked": false
          },
          "type": "bar",
          "version": "v1"
        },
        "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
        "outputId": "2e43a56c-25db-4b9a-d921-4124e74deb7a"
      },
      "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/com.datacamp.data-table.v2+json": {
              "table": {
                "schema": {
                  "fields": [
                    {
                      "name": "index",
                      "type": "integer"
                    },
                    {
                      "name": "0",
                      "type": "string"
                    },
                    {
                      "name": "1",
                      "type": "string"
                    },
                    {
                      "name": "2",
                      "type": "number"
                    },
                    {
                      "name": "3",
                      "type": "string"
                    },
                    {
                      "name": "4",
                      "type": "string"
                    },
                    {
                      "name": "5",
                      "type": "string"
                    },
                    {
                      "name": "6",
                      "type": "string"
                    },
                    {
                      "name": "7",
                      "type": "number"
                    },
                    {
                      "name": "8",
                      "type": "string"
                    },
                    {
                      "name": "9",
                      "type": "string"
                    },
                    {
                      "name": "10",
                      "type": "integer"
                    },
                    {
                      "name": "11",
                      "type": "string"
                    },
                    {
                      "name": "12",
                      "type": "integer"
                    },
                    {
                      "name": "13",
                      "type": "string"
                    }
                  ],
                  "primaryKey": [
                    "index"
                  ],
                  "pandas_version": "1.4.0"
                },
                "data": {
                  "0": [
                    "b",
                    "a",
                    "a",
                    "b",
                    "b"
                  ],
                  "1": [
                    "30.83",
                    "58.67",
                    "24.50",
                    "27.83",
                    "20.17"
                  ],
                  "2": [
                    0,
                    4.46,
                    0.5,
                    1.54,
                    5.625
                  ],
                  "3": [
                    "u",
                    "u",
                    "u",
                    "u",
                    "u"
                  ],
                  "4": [
                    "g",
                    "g",
                    "g",
                    "g",
                    "g"
                  ],
                  "5": [
                    "w",
                    "q",
                    "q",
                    "w",
                    "w"
                  ],
                  "6": [
                    "v",
                    "h",
                    "h",
                    "v",
                    "v"
                  ],
                  "7": [
                    1.25,
                    3.04,
                    1.5,
                    3.75,
                    1.71
                  ],
                  "8": [
                    "t",
                    "t",
                    "t",
                    "t",
                    "t"
                  ],
                  "9": [
                    "t",
                    "t",
                    "f",
                    "t",
                    "f"
                  ],
                  "10": [
                    1,
                    6,
                    0,
                    5,
                    0
                  ],
                  "11": [
                    "g",
                    "g",
                    "g",
                    "g",
                    "s"
                  ],
                  "12": [
                    0,
                    560,
                    824,
                    3,
                    0
                  ],
                  "13": [
                    "+",
                    "+",
                    "+",
                    "+",
                    "+"
                  ],
                  "index": [
                    0,
                    1,
                    2,
                    3,
                    4
                  ]
                }
              },
              "total_rows": 5,
              "truncation_type": null
            },
            "text/plain": "  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>g</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>g</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>g</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>g</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>s</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We use df.info() to obtain a concise summary of the DataFrame's structure and contents. This method provides valuable information such as the number of entries, the number of non-null values in each column, and the data type of each column."
      ],
      "metadata": {
        "id": "tnVDbT6sAkHJ"
      },
      "id": "tnVDbT6sAkHJ"
    },
    {
      "source": [
        "#Check if the data contains any nulls and dtypes of the columns\n",
        "cc_apps.info()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 54,
        "lastExecutedAt": 1714671341427,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Check if the data contains any nulls and dtypes of the columns\ncc_apps.info()",
        "outputsMetadata": {
          "0": {
            "height": 458,
            "type": "stream"
          }
        },
        "id": "5fb498e8-a080-457d-a8ba-d72b1527e25e",
        "outputId": "c3323488-7cfd-4480-d316-24d8f178826c"
      },
      "cell_type": "code",
      "id": "5fb498e8-a080-457d-a8ba-d72b1527e25e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 690 entries, 0 to 689\nData columns (total 14 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       690 non-null    object \n 1   1       690 non-null    object \n 2   2       690 non-null    float64\n 3   3       690 non-null    object \n 4   4       690 non-null    object \n 5   5       690 non-null    object \n 6   6       690 non-null    object \n 7   7       690 non-null    float64\n 8   8       690 non-null    object \n 9   9       690 non-null    object \n 10  10      690 non-null    int64  \n 11  11      690 non-null    object \n 12  12      690 non-null    int64  \n 13  13      690 non-null    object \ndtypes: float64(2), int64(2), object(10)\nmemory usage: 75.6+ KB\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "The following code essentially handles missing values in the dataset by replacing them with appropriate values based on the data type of each column. For categorical columns, it uses the most frequent value, and for numerical columns, it uses the mean."
      ],
      "metadata": {
        "id": "4i2RjAdJAo0X"
      },
      "id": "4i2RjAdJAo0X"
    },
    {
      "source": [
        "# Replace the '?'s with NaN in dataset\n",
        "cc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n",
        "\n",
        "# Create a copy of the NaN replacement DataFrame\n",
        "cc_apps_imputed = cc_apps_nans_replaced.copy()\n",
        "\n",
        "# Iterate over each column of cc_apps_nans_replaced and impute the most frequent value for object data types and the mean for numeric data types\n",
        "for col in cc_apps_imputed.columns:\n",
        "    # Check if the column is of object type\n",
        "    if cc_apps_imputed[col].dtypes == \"object\":\n",
        "        # Impute with the most frequent value\n",
        "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n",
        "            cc_apps_imputed[col].value_counts().index[0]\n",
        "        )\n",
        "    else:\n",
        "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 58,
        "lastExecutedAt": 1714671341485,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Replace the '?'s with NaN in dataset\ncc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n\n# Create a copy of the NaN replacement DataFrame\ncc_apps_imputed = cc_apps_nans_replaced.copy()\n\n# Iterate over each column of cc_apps_nans_replaced and impute the most frequent value for object data types and the mean for numeric data types\nfor col in cc_apps_imputed.columns:\n    # Check if the column is of object type\n    if cc_apps_imputed[col].dtypes == \"object\":\n        # Impute with the most frequent value\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n            cc_apps_imputed[col].value_counts().index[0]\n        )\n    else:\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())",
        "id": "307222c3-98ba-452c-89c3-22055c4054ac"
      },
      "cell_type": "code",
      "id": "307222c3-98ba-452c-89c3-22055c4054ac",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting DataFrame\n",
        "\n",
        "```\n",
        "cc_apps_encoded\n",
        "```\n",
        " will have the original numerical columns along with new columns representing the one-hot encoded categorical variables. Each category in a categorical variable will be represented by a binary column (0 or 1) indicating its presence or absence. This encoding is commonly used for preprocessing data before applying machine learning algorithms, especially with models that require numerical input."
      ],
      "metadata": {
        "id": "9B-p5nB2BujR"
      },
      "id": "9B-p5nB2BujR"
    },
    {
      "source": [
        "# Dummify the categorical features\n",
        "cc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 52,
        "lastExecutedAt": 1714671341537,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Dummify the categorical features\ncc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)",
        "id": "fed1d756-97d9-436b-bbf6-77c52102e7b2"
      },
      "cell_type": "code",
      "id": "fed1d756-97d9-436b-bbf6-77c52102e7b2",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The preprocessed data is then divided into 2 parts: X - the part of the dataframe without the labels and y - The column containing the lables of the data."
      ],
      "metadata": {
        "id": "lrnKGxiuB7kw"
      },
      "id": "lrnKGxiuB7kw"
    },
    {
      "source": [
        "# Get X - data without label and y-labels for Modeling\n",
        "X = cc_apps_encoded.iloc[:, :-1].values\n",
        "y = cc_apps_encoded.iloc[:, [-1]].values"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 52,
        "lastExecutedAt": 1714671341589,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Get X - data without label and y-labels for Modeling\nX = cc_apps_encoded.iloc[:, :-1].values\ny = cc_apps_encoded.iloc[:, [-1]].values",
        "id": "32feaa79-fade-4570-8ed0-b3e90cce44c9"
      },
      "cell_type": "code",
      "id": "32feaa79-fade-4570-8ed0-b3e90cce44c9",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data\n",
        "The `train_test_split` module from the `sklearn.model_selection` package is used to divide the X and y into `X_train, X_test, y_train and y_test ` for training our model. We chose the test size to be 20%. This can be changed as per need."
      ],
      "metadata": {
        "id": "y5Q6AVmnCTsr"
      },
      "id": "y5Q6AVmnCTsr"
    },
    {
      "source": [
        "#Use the Train and test split to divide data into 80% - train and 20% - test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 52,
        "lastExecutedAt": 1714671341641,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Use the Train and test split to divide data into 80% - train and 20% - test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)",
        "id": "1ecf2688-652e-4f92-99c2-4d927f0b9bef"
      },
      "cell_type": "code",
      "id": "1ecf2688-652e-4f92-99c2-4d927f0b9bef",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the data\n",
        "The `StandardScaler()` function from the `sklearn.preprocessing` module is used for standardizing features by removing the mean and scaling them to unit variance"
      ],
      "metadata": {
        "id": "68G4YoClDEg6"
      },
      "id": "68G4YoClDEg6"
    },
    {
      "source": [
        "#Use Standard Scaler to scale the values\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 48,
        "lastExecutedAt": 1714671341689,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Use Standard Scaler to scale the values\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
        "id": "1725dd2c-8240-4ab6-af23-3cbfe28668fc"
      },
      "cell_type": "code",
      "id": "1725dd2c-8240-4ab6-af23-3cbfe28668fc",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning\n",
        "Creating a paramter grid for testing various combinations through the GridSearchCV model for hyperparameter Tuning. This will allow us to use the best possible parameters for our machine learning model."
      ],
      "metadata": {
        "id": "7Omgq-JHDUNG"
      },
      "id": "7Omgq-JHDUNG"
    },
    {
      "source": [
        "#Initialize parameters for the Logistic Regression model to find the best combination\n",
        "tol = [0.01,0.001,0.0001]\n",
        "max_iter = [100,200,150]\n",
        "param_grid = {'tol':tol,'max_iter':max_iter}"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 48,
        "lastExecutedAt": 1714671341737,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Initialize parameters for the Logistic Regression model to find the best combination\ntol = [0.01,0.001,0.0001]\nmax_iter = [100,200,150]\nparam_grid = {'tol':tol,'max_iter':max_iter}",
        "id": "b2f7e85d-84a2-481b-a88f-e724ed5a0f68"
      },
      "cell_type": "code",
      "id": "b2f7e85d-84a2-481b-a88f-e724ed5a0f68",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the data using GridSearchCV to get the best parameters."
      ],
      "metadata": {
        "id": "DIEo4epmDtFr"
      },
      "id": "DIEo4epmDtFr"
    },
    {
      "source": [
        "#Create an object of GridSearchCV class to find the best parameters\n",
        "search_grid = GridSearchCV(\n",
        "    estimator = logreg , param_grid = param_grid, cv= 5\n",
        ")\n",
        "search_grid.fit(X_train_scaled,y_train)\n",
        "\n",
        "#Print the best paramters\n",
        "print(search_grid.best_params_)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 7336,
        "lastExecutedAt": 1714671349073,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Create an object of GridSearchCV class to find the best parameters\nsearch_grid = GridSearchCV(\n    estimator = logreg , param_grid = param_grid, cv= 5\n)\nsearch_grid.fit(X_train_scaled,y_train)\n\n#Print the best paramters\nprint(search_grid.best_params_)",
        "outputsMetadata": {
          "0": {
            "height": 38,
            "type": "stream"
          }
        },
        "id": "e8dbf62c-f48e-49f2-8428-1cb9bbb07a3e",
        "outputId": "ebc6dcb4-f446-48c8-f1e8-2806e6932a12"
      },
      "cell_type": "code",
      "id": "e8dbf62c-f48e-49f2-8428-1cb9bbb07a3e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'max_iter': 100, 'tol': 0.01}\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Logistic Regression Model\n",
        "Training the logistic regression model with the values of the hyperparameters obtained in the previous step. We also print a confusion matrix to check our model performance."
      ],
      "metadata": {
        "id": "GxZAOMm_D0pd"
      },
      "id": "GxZAOMm_D0pd"
    },
    {
      "source": [
        "#Using the best parameters create an instance of the LogisticRegression model\n",
        "log_reg = LogisticRegression(max_iter = 100, tol = 0.01)\n",
        "\n",
        "#Fit the model\n",
        "log_reg.fit(X_train_scaled,y_train)\n",
        "\n",
        "#Use the model to predict values\n",
        "y_pred_new = log_reg.predict(X_test_scaled)\n",
        "\n",
        "#Print the confusion matrix\n",
        "print(confusion_matrix(y_test,y_pred_new))"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 290,
        "lastExecutedAt": 1714671349363,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#Using the best parameters create an instance of the LogisticRegression model\nlog_reg = LogisticRegression(max_iter = 100, tol = 0.01)\n\n#Fit the model\nlog_reg.fit(X_train_scaled,y_train)\n\n#Use the model to predict values\ny_pred_new = log_reg.predict(X_test_scaled)\n\n#Print the confusion matrix\nprint(confusion_matrix(y_test,y_pred_new))",
        "outputsMetadata": {
          "0": {
            "height": 59,
            "type": "stream"
          }
        },
        "id": "ed20fef3-a885-4165-9202-8e9518ad8521",
        "outputId": "f1139547-e96f-4693-954b-df32bbd34b84"
      },
      "cell_type": "code",
      "id": "ed20fef3-a885-4165-9202-8e9518ad8521",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[52 18]\n [12 56]]\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Model Score"
      ],
      "metadata": {
        "id": "DXQ0zNb_EESA"
      },
      "id": "DXQ0zNb_EESA"
    },
    {
      "source": [
        "# Score from the best fit model\n",
        "best_score = log_reg.score(X_test_scaled,y_test)\n",
        "print(f'The score of the model is {round(best_score*100,2)}')"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 102,
        "lastExecutedAt": 1714671349466,
        "lastExecutedByKernel": "78097adc-1bab-4880-9c4f-a5df586d20ef",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Score from the best fit model\nbest_score = log_reg.score(X_test_scaled,y_test)\nprint(best_score)",
        "outputsMetadata": {
          "0": {
            "height": 38,
            "type": "stream"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db19712e-f8a6-4b02-9aeb-637012e73470",
        "outputId": "e29f77f1-42dc-43d2-b572-bc324b190482"
      },
      "cell_type": "code",
      "id": "db19712e-f8a6-4b02-9aeb-637012e73470",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score of the model is 78.26\n"
          ]
        }
      ],
      "execution_count": 2
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "editor": "DataCamp Workspace"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}